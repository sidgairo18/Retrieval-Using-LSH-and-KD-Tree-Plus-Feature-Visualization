{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbour Extraction using Gram Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kshitij98/getNeighbours/venv/bin/python3\n",
      "3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Helper import getDataLoader, getNames, dist\n",
    "from ipynb.fs.full.GramMatrix import convertModel, GramMatrixLayer\n",
    "from ipynb.fs.full.LabelDataset import createDirectories\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = getDataLoader('/scratch/bam_subset_2_0_labeled', batch_size=4, shuffle=True, num_workers=4, testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "vgg19 = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramMatrixLayers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1']\n",
    "gramMatrixWeights = [1, 1, 1, 1]\n",
    "vgg19, model, gram_matrices = convertModel(vgg19, gramMatrixLayers, gramMatrixWeights, testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1_1): ReLU()\n",
       "  (gram_matrix1_1): GramMatrixLayer(λ=1)\n",
       "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1_2): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2_1): ReLU()\n",
       "  (gram_matrix2_1): GramMatrixLayer(λ=1)\n",
       "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2_2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_1): ReLU()\n",
       "  (gram_matrix3_1): GramMatrixLayer(λ=1)\n",
       "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_2): ReLU()\n",
       "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_3): ReLU()\n",
       "  (conv3_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_4): ReLU()\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_1): ReLU()\n",
       "  (gram_matrix4_1): GramMatrixLayer(λ=1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174560\n"
     ]
    }
   ],
   "source": [
    "dataIter = iter(loader)\n",
    "\n",
    "(data, classes), names = dataIter.next()\n",
    "data = data.cuda()\n",
    "out = model(data)\n",
    "G = []\n",
    "for layer in gram_matrices:\n",
    "    G.append(layer.gramMatrix)\n",
    "G = torch.cat(G, 1)\n",
    "\n",
    "a, D = G.size()\n",
    "\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Random Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a ‘safe’ number of components to randomly project to\n",
    "\n",
    "The distortion introduced by a random projection p only changes the distance between two points by a factor (1 +- eps) in an euclidean space with good probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "\n",
    "# TODO: Remove hardcoded dataset size\n",
    "K = johnson_lindenstrauss_min_dim(40474, eps=0.3)\n",
    "\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174560, 2000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.random_projection import gaussian_random_matrix\n",
    "\n",
    "K = 2000\n",
    "D = 174560\n",
    "\n",
    "RPM = gaussian_random_matrix(K, D)\n",
    "RPM = RPM.transpose()\n",
    "print(RPM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating /scratch/kshitij98\n",
      "torch.Size([174560, 2000])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "if not os.path.exists('/scratch/kshitij98'):\n",
    "    print(\"Creating\", '/scratch/kshitij98')\n",
    "    os.makedirs('/scratch/kshitij98')\n",
    "\n",
    "RPM = torch.from_numpy(RPM)\n",
    "RPM = RPM.cuda()\n",
    "RPM = RPM.float()\n",
    "print(RPM.shape)\n",
    "\n",
    "torch.save(RPM, \"/scratch/kshitij98/rpm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Incremental PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPM = torch.load('/scratch/kshitij98/pca1000.tensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPM = RPM.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RPM.shape)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "createDirectories('/scratch/bam_subset_2_0_raw_features/')\n",
    "\n",
    "dataIter = iter(loader)\n",
    "t = time.time()\n",
    "\n",
    "# TODO: Remove hardcoded dataset size\n",
    "i = 1\n",
    "while i <= 5000:\n",
    "    (data, classes), names = dataIter.next()\n",
    "    data = data.cuda()\n",
    "    out = model(data)\n",
    "    G = []\n",
    "    for layer in gram_matrices:\n",
    "        G.append(layer.gramMatrix)\n",
    "    G = torch.cat(G, 1)\n",
    "    if i == 1:\n",
    "        print(G.shape, \"\\n\\n\")\n",
    "#     for j, gm in enumerate(G):\n",
    "#         print(names[j])\n",
    "#     break\n",
    "#         torch.save(gm, names[j].replace('imdb_dataset', 'imdb_dataset_features'))\n",
    "#     G = torch.mm(G, RPM)\n",
    "    for j, gm in enumerate(G):\n",
    "#         print(names[j])\n",
    "        torch.save(gm, names[j].replace('bam_subset_2_0_labeled', 'bam_subset_2_0_raw_features'))\n",
    "    print(i, \"\\tETA: \", ((time.time() - t) / ((i) * 4)) * (20000 - ((i) * 4)) * (1 / 60), \"minutes\", end='\\r')\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "names = getNames('/scratch/bam_subset_2_0_features/')\n",
    "X = []\n",
    "for i, fileName in enumerate(names):\n",
    "    X.append(torch.load(fileName))\n",
    "    print(\"ETA: \", (len(names) - i - 1) * ((time.time() - t) / (i+1)), end='\\r')\n",
    "X = torch.stack(X, 0)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# createDirectories('/scratch/bam_subset_2_0_top_neighbours/')\n",
    "createDirectories('/scratch/bam_subset_2_0_bottom_neighbours/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT USE\n",
    "# Negation of MSE\n",
    "\n",
    "import torch\n",
    "\n",
    "C = 0.25 * torch.ones(1)\n",
    "C = C.cuda()\n",
    "\n",
    "def bDist(n1, n2, C):\n",
    "    assert(n1.size(0) == 1)\n",
    "\n",
    "    s1 = n1.size(0)\n",
    "    s2 = n2.size(0)\n",
    "    d = n1.size(1)\n",
    "    \n",
    "    n1 = n1.expand(s2, d)\n",
    "    C = C.expand(s2, d)\n",
    "    n2 = torch.sum((C - torch.min(torch.abs(torch.sub(n1, n2)), C)) ** 4, 1)\n",
    "\n",
    "    return n2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    A = torch.ones(1, 10)\n",
    "    B = 1.5* torch.ones(7, 10)\n",
    "    A = A.cuda()\n",
    "    B = B.cuda()\n",
    "    print(bDist(A, B, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # from ipynb.fs.full.Helper import bDist\n",
    "\n",
    "\n",
    "# k = 15\n",
    "# t = time.time()\n",
    "# names = getNames('/scratch/bam_subset_2_0_features/')\n",
    "\n",
    "\n",
    "\n",
    "# for i, source in enumerate(X):\n",
    "# #     if i < 25000:\n",
    "# #         continue\n",
    "    \n",
    "# #     if i > 25000 + 200:\n",
    "# #         break\n",
    "    \n",
    "#     source = torch.unsqueeze(source, 0)\n",
    "\n",
    "# #     d = dist(source, X)\n",
    "# #     d, indices = d.sort()\n",
    "\n",
    "#     bD = bDist(source, X, C)\n",
    "#     bD, bIndices = bD.sort()\n",
    "\n",
    "# #     topIds = indices[0, 1:k+1]\n",
    "#     # Note: Negative slicing is not supported\n",
    "#     bottomIds = bIndices[0:k]\n",
    "\n",
    "# #     top = []\n",
    "# #     for idx in topIds:\n",
    "# # #         print(idx)\n",
    "# #         top.append(names[idx].replace('bam_subset_2_0_features', 'bam_subset_2_0_labeled'))\n",
    "# #     top = np.asarray(top)\n",
    "    \n",
    "#     bottom = []\n",
    "#     for idx in bottomIds:\n",
    "#         bottom.append(names[idx])\n",
    "#     bottom = np.asarray(bottom)\n",
    "    \n",
    "# #     np.save(names[i].replace('bam_subset_2_0_features', 'bam_subset_2_0_top_neighbours'), top)\n",
    "#     np.save(names[i].replace('bam_subset_2_0_features', 'bam_subset_2_0_bottom_neighbours'), bottom)\n",
    "\n",
    "#     print(\"ETA: \", (len(X) - i - 1) * ((time.time() - t) / (i+1)) * (1 / 60), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fileName = '/scratch/kshitij98/cluster1-1-1-1_7.pkl'\n",
    "kmeans = pickle.load(open(fileName, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = torch.from_numpy(kmeans.cluster_centers_)\n",
    "centers = centers.float().cuda()\n",
    "print(type(centers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(torch.unsqueeze(X[0], 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFarthestCluster(source):\n",
    "    maxDist = None\n",
    "    farthestCluster = None\n",
    "    distances = dist(source, centers)\n",
    "    distances = torch.squeeze(distances, 0)\n",
    "    for i, d in enumerate(distances):\n",
    "        if maxDist is None or d > maxDist:\n",
    "            farthestCluster = i\n",
    "            maxDist = d\n",
    "#     print(farthestCluster, maxDist)\n",
    "    return farthestCluster\n",
    "\n",
    "def getClusters(source):\n",
    "    distances = dist(source, centers)\n",
    "    distances, indices = distances.sort()\n",
    "    return distances, indices\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    getFarthestCluster(torch.unsqueeze(X[32451], 0))\n",
    "    distances, indices = getClusters(torch.unsqueeze(X[125234], 0))\n",
    "    print(distances, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sampleIdx = list(range(0, X.shape[0]))\n",
    "print(len(sampleIdx))\n",
    "print(sampleIdx[0])\n",
    "random.shuffle(sampleIdx)\n",
    "print(sampleIdx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fX = {}\n",
    "fXIds = {}\n",
    "\n",
    "names = getNames('/scratch/bam_subset_2_0_features/')\n",
    "\n",
    "for i, sample in enumerate(X):\n",
    "    if fX.get(kmeansC.labels_[i]) is None:\n",
    "        fX[kmeansC.labels_[i]] = []\n",
    "        fXIds[kmeansC.labels_[i]] = []\n",
    "    fX[kmeansC.labels_[i]].append(sample)\n",
    "    fXIds[kmeansC.labels_[i]].append(i)\n",
    "\n",
    "    print(i, end='\\r')\n",
    "    \n",
    "print(fX.shape)\n",
    "#     print(cluster.contains(kmeansC[i]))\n",
    "#     if clusters[kmeansC[i]]:\n",
    "        \n",
    "    \n",
    "#     if i == 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 5\n",
    "t = time.time()\n",
    "no_of_samples = 5\n",
    "# Scale the dataset\n",
    "# X = X ** 0.8\n",
    "\n",
    "N = 100\n",
    "K = 15\n",
    "names = getNames('/scratch/bam_subset_2_0_features/')\n",
    "\n",
    "filteredX = \n",
    "\n",
    "for i, sampleId in enumerate(sampleIdx):\n",
    "    source = torch.unsqueeze(X[sampleId], 0)\n",
    "\n",
    "    d = dist(source, X)\n",
    "    d, indices = d.sort()\n",
    "\n",
    "#     topIds = indices[0, 1:k+1]\n",
    "    # # Note: Negative slicing is not supported, Need to reverse\n",
    "#     farthestCluster = getFarthestCluster(source)\n",
    "#     ClusterDist, ClusterIdx = getClusters(source)\n",
    "#     print(ClusterDist, ClusterIdx)\n",
    "    bottomIds = []\n",
    "    bottomIds2 = []\n",
    "    bottomSamples = []\n",
    "    for c in range(len(kmeans.cluster_centers_)):\n",
    "        if c != kmeans.labels_(sampleId):\n",
    "            randomIds = list(range(0, len(fX[c])))\n",
    "            random.shuffle(randomIds)\n",
    "            for j in range(no_of_samples):\n",
    "                bottomIds2.append(fXIds[c][randomIds[j]])\n",
    "                bottomSamples.append(fX[c][randomIds[j]])\n",
    "\n",
    "    bD = dist(source, bottomSamples)\n",
    "    bD, bIndices = bD.sort()\n",
    "\n",
    "    cnt = 0\n",
    "    for j in reversed(bIndices):\n",
    "        bottomIds.append(bottomIds2[j])\n",
    "        \n",
    "        cnt += 1\n",
    "        if cnt == K:\n",
    "            break\n",
    "\n",
    "#     top = []\n",
    "#     for idx in topIds:\n",
    "#         top.append(names[idx].replace('bam_subset_2_0_features', 'bam_subset_2_0_labeled'))\n",
    "#     top = np.asarray(top)\n",
    "    \n",
    "    bottom = []\n",
    "    for idx in bottomIds:\n",
    "        bottom.append(names[idx].replace('bam_subset_2_0_features', 'bam_subset_2_0_labeled'))\n",
    "    bottom = np.asarray(bottom)\n",
    "    \n",
    "#     np.save(names[sampleId].replace('bam_subset_2_0_features', 'bam_subset_2_0_top_neighbours'), top)\n",
    "    np.save(names[sampleId].replace('bam_subset_2_0_features', 'bam_subset_2_0_bottom_neighbours'), bottom)\n",
    "\n",
    "    print(\"ETA: \", (N - i - 1) * ((time.time() - t) / (i+1)), end='\\r')\n",
    "    \n",
    "    if i == N:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(3, 3)\n",
    "print(A)\n",
    "print(A**0.8)\n",
    "print(A*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "names = getNames('/scratch/bam_subset_2_0_top_neighbours/', shuffle=True)\n",
    "bNames = getNames('/scratch/bam_subset_2_0_bottom_neighbours/', shuffle=True)\n",
    "\n",
    "def showImages(images):\n",
    "    fig = plt.figure(figsize=(32, 32))\n",
    "    columns = 5\n",
    "    rows = 4\n",
    "    for i in range(1, len(images) + 1):\n",
    "        img = images[i-1]\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# idx = 0\n",
    "# def showNeighbours(index = None):\n",
    "#     global idx\n",
    "#     if index is not None:\n",
    "#         idx = index\n",
    "#     nbs = np.load(names[idx])\n",
    "#     bNbs = np.load(bNames[idx])\n",
    "#     images = []\n",
    "#     nImages = []\n",
    "#     print(names[idx])\n",
    "#     images.append(Image.open(names[idx].replace('_top_neighbours', '_labeled').replace('.npy', '')))\n",
    "#     nImages.append(Image.open(bNames[idx].replace('_bottom_neighbours', '_labeled').replace('.npy', '')))\n",
    "#     for nb in nbs:\n",
    "# #         print(\"NB\", nb)\n",
    "# #         nb = nb.replace('bam_subset_2_0', 'bam_subset_2_0_labeled')\n",
    "#         images.append(Image.open(nb))\n",
    "#     for nb in bNbs:\n",
    "# #         print(\"NB\", nb)\n",
    "# #         nb = nb.replace('bam_subset_2_0_features', 'bam_subset_2_0_labeled')\n",
    "#         nImages.append(Image.open(nb))\n",
    "# #     showImages(images)\n",
    "# #     showImages(nImages)\n",
    "#     idx += 1\n",
    "#     return nbs, bNbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showNeighbours(imagePath):\n",
    "    images = []\n",
    "#     imageName = imagePath.replace('_top_neighbours', '_labeled')\n",
    "#     imageName = imageName.replace('_bottom_neighbours', '_labeled')\n",
    "#     images.append(Image.open(imageName.replace('.npy', '')))\n",
    "    nbs = np.load(imagePath)\n",
    "#     showImages(images)\n",
    "    return nbs    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitatively test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripName(name, count = 2, char = '/'):\n",
    "    ls = name.split(char)\n",
    "    name = char.join(ls[-count:])\n",
    "    name = name.strip('.npy')\n",
    "    return name\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    stripName('/scratch/bam_subset_2_0_labeled/10/140449313_20919783.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imageSet = set()\n",
    "names = getNames('/scratch/bam_subset_2_0_top_neighbours/', shuffle=True)\n",
    "for i, name in enumerate(names):\n",
    "    arr = []\n",
    "    arr.append(stripName(name, 1))\n",
    "    imageSet.add(stripName(name))\n",
    "    top = showNeighbours(name)\n",
    "    for t in top:\n",
    "        arr.append(stripName(t, 1))\n",
    "        imageSet.add(stripName(t))\n",
    "    print(arr, end=',\\n\\n')\n",
    "        \n",
    "print(len(imageSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imageSet = set()\n",
    "names = getNames('/scratch/bam_subset_2_0_bottom_neighbours/', shuffle=True)\n",
    "for i, name in enumerate(names):\n",
    "    arr = []\n",
    "    arr.append(stripName(name, 1))\n",
    "    imageSet.add(stripName(name))\n",
    "    bottom = showNeighbours(name)\n",
    "    for b in bottom:\n",
    "        arr.append(stripName(b, 1))\n",
    "        imageSet.add(stripName(b))\n",
    "    print(arr, end=',\\n\\n')\n",
    "        \n",
    "print(len(imageSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name in imageSet:\n",
    "    print('/scratch/bam_subset_2_0_labeled/' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "labels = None\n",
    "with open('../bam_2_0_image_style_labels.pkl', 'rb') as handle:\n",
    "    labels = pickle.load(handle)\n",
    "\n",
    "print(len(labels))\n",
    "\n",
    "idx2 = 0\n",
    "\n",
    "names = getNames('/scratch/bam_subset_2_0_top_neighbours/', shuffle=True)\n",
    "\n",
    "def getTopAccuracy(n):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    mini = 1000000\n",
    "    worst = None\n",
    "    for i in range(n):\n",
    "        truth = labels[names[i].split('/')[-1].replace('.npy', '')]\n",
    "        nbs = np.load(names[i])\n",
    "#         print(truth)\n",
    "        curr = 0\n",
    "        l = []\n",
    "        for nb in nbs:\n",
    "            nb = nb.split('/')[-1]\n",
    "            l.append(labels[nb])\n",
    "            if truth == labels[nb]:\n",
    "                curr += 1\n",
    "#             print(labels[nb])\n",
    "            total += 1\n",
    "        if curr < mini:\n",
    "            mini = curr\n",
    "            worst = i\n",
    "            actual = truth\n",
    "            nb_labels = l\n",
    "        correct += curr\n",
    "    showNeighbours(worst)\n",
    "    print(mini, \" / 15 are correct neighbours\")\n",
    "    print(\"Actual label\", actual)\n",
    "    print(\"Neighbour labels: \", nb_labels)\n",
    "    return str((correct / total) * 100) + \" %\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getTopAccuracy(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = 10000\n",
    "maxi = -10000\n",
    "for i, x in enumerate(X):\n",
    "#     print(i, x)\n",
    "#     print(min(x), max(x))\n",
    "    mini = min(min(x), mini)\n",
    "    maxi = max(max(x), maxi)\n",
    "    if i == 1000:\n",
    "        break\n",
    "print(mini, maxi)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
